# Generated by Django 4.2.16 on 2025-11-06 07:36

from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='DashCardCache',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('key', models.CharField(db_index=True, help_text='如: overview_trend, heatmap_category, publisher_stats 等', max_length=200, unique=True, verbose_name='缓存键')),
                ('snapshot', models.JSONField(help_text='ECharts 配置或数据对象', verbose_name='数据快照')),
                ('description', models.CharField(blank=True, default='', max_length=500, verbose_name='描述')),
                ('updated_at', models.DateTimeField(auto_now=True, db_index=True, verbose_name='更新时间')),
            ],
            options={
                'verbose_name': '仪表盘缓存',
                'verbose_name_plural': '仪表盘缓存',
                'db_table': 'dash_card_cache',
                'ordering': ['-updated_at'],
            },
        ),
        migrations.CreateModel(
            name='RawCrawl',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('source', models.CharField(db_index=True, help_text='如: steam, epic, gog 等', max_length=100, verbose_name='数据源')),
                ('payload', models.JSONField(help_text='原始JSON数据', verbose_name='数据载荷')),
                ('hash', models.CharField(db_index=True, help_text='用于去重的数据哈希值', max_length=64, unique=True, verbose_name='数据哈希')),
                ('created_at', models.DateTimeField(auto_now_add=True, db_index=True, verbose_name='创建时间')),
            ],
            options={
                'verbose_name': '原始爬取数据',
                'verbose_name_plural': '原始爬取数据',
                'db_table': 'raw_crawls',
                'ordering': ['-created_at'],
                'indexes': [models.Index(fields=['source', '-created_at'], name='raw_crawls_source_f81ceb_idx')],
            },
        ),
        migrations.CreateModel(
            name='CrawlJob',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('source', models.CharField(db_index=True, max_length=100, verbose_name='数据源')),
                ('status', models.CharField(choices=[('running', '运行中'), ('success', '成功'), ('failed', '失败')], db_index=True, default='running', max_length=20, verbose_name='状态')),
                ('items_count', models.IntegerField(default=0, verbose_name='抓取条数')),
                ('error_message', models.TextField(blank=True, default='', verbose_name='错误信息')),
                ('started_at', models.DateTimeField(auto_now_add=True, db_index=True, verbose_name='开始时间')),
                ('finished_at', models.DateTimeField(blank=True, null=True, verbose_name='结束时间')),
            ],
            options={
                'verbose_name': '爬虫任务',
                'verbose_name_plural': '爬虫任务',
                'db_table': 'crawl_jobs',
                'ordering': ['-started_at'],
                'indexes': [models.Index(fields=['source', '-started_at'], name='crawl_jobs_source_2bd7ac_idx'), models.Index(fields=['status', '-started_at'], name='crawl_jobs_status_b68ace_idx')],
            },
        ),
    ]
